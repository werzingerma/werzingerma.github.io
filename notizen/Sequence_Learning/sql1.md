---
layout: page
title: SQL1 - comparing sequences
permalink: /notizen/Sequence_Learning/sql1/
---

# comparing sequences

## 1. Hamming-Abstand

Der **Hamming-Abstand** zÃ¤hlt, **wie viele Stellen sich zwei gleich lange Bitfolgen unterscheiden**.

### Beispiel:
```
A: 1 0 1 1 0 0 1  
B: 1 0 0 1 1 0 1

Unterschiede an Position 3 und 5  
â†’ Hamming-Abstand = 2
```

### Anwendung:
- Vergleich von Audiosignalen oder BinÃ¤rmerkmalen
- Fehlererkennung bei DatenÃ¼bertragung

ðŸ”— [Wikipedia: Hamming-Abstand](https://de.wikipedia.org/wiki/Hamming-Abstand)

---

## 2. Edit-/Levenshtein-Abstand

ZÃ¤hlt die **minimale Anzahl an Operationen** (EinfÃ¼gen, LÃ¶schen, Ersetzen), um eine Zeichenfolge in eine andere umzuwandeln.

### Beispiel:
```
"kitten" â†’ "sitting"
1. kitten â†’ sitten   (k â†’ s)
2. sitten â†’ sittin   (e â†’ i)
3. sittin â†’ sitting  (g anhÃ¤ngen)

â†’ Levenshtein-Abstand = 3
```

### Anwendung:
- Spracherkennung (z.â€¯B. erkannte WÃ¶rter vs. Zieltext)
- Rechtschreibkorrektur
- Ã„hnlichkeitsmessung

ðŸ”— [Wikipedia: Levenshtein-Distanz](https://de.wikipedia.org/wiki/Levenshtein-Distanz)

---

## 3. Edit-Transcript / Alignment

Das **Edit-Transcript** beschreibt die **Reihenfolge der Schritte** (Insert, Delete, Substitute), um eine Sequenz in eine andere zu Ã¼berfÃ¼hren.

### Beispiel:
```
A: kitten  
B: sitting

Transcript:
S(k â†’ s), S(e â†’ i), I(g)

Alignment (vereinfacht):
k i t t e n
| | | | | |
s i t t i n g
```

### Anwendung:
- Visualisierung von Fehlern bei automatischer Spracherkennung
- Auswertung von Vorhersagegenauigkeit

ðŸ”— [Lecture Slide Beispiel (engl.) mit Edit Transcripts](https://web.stanford.edu/class/cs124/lec/med.pdf)

---


## 4. Dynamische Programmierung (DP)

**Grundprinzip**, bei dem groÃŸe Probleme in **Ã¼berlappende Teilprobleme** zerlegt und deren LÃ¶sungen **gespeichert (Memoization)** werden.

---

### Beispiel fÃ¼r Levenshtein (kitten â†’ sitting)

Wir berechnen die minimale Anzahl von EinfÃ¼ge-, LÃ¶sch- oder Ersetz-Operationen, um "kitten" in "sitting" zu verwandeln.

**WÃ¶rter:**
- Quelle: `kitten`
- Ziel: `sitting`

Initiale Matrix (inkl. leere Zeichen "" vorangestellt):

|   |   | s | i | t | t | i | n | g |
|---|---|---|---|---|---|---|---|---|
|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |
| k | 1 |   |   |   |   |   |   |   |
| i | 2 |   |   |   |   |   |   |   |
| t | 3 |   |   |   |   |   |   |   |
| t | 4 |   |   |   |   |   |   |   |
| e | 5 |   |   |   |   |   |   |   |
| n | 6 |   |   |   |   |   |   |   |

**FÃ¼llregel:**
- Wenn Buchstaben gleich â†’ cost = 0
- Sonst â†’ cost = 1
- Zelle = min(EinfÃ¼gen, LÃ¶schen, Ersetzen) + cost

Wir fÃ¼llen die Matrix zeilenweise, z.â€¯B.:
- FÃ¼r Zelle (1,1): `k` vs. `s` â†’ cost = 1 â†’ min(1, 1, 0) + 1 = 1
- FÃ¼r Zelle (2,2): `i` vs. `i` â†’ cost = 0 â†’ min(2, 2, 1) + 0 = 1
- usw.

Am Ende steht in der rechten unteren Ecke die LÃ¶sung: **3**

â†’ **Levenshtein-Abstand("kitten", "sitting") = 3**

---

### Beispiel fÃ¼r DTW (Dynamic Time Warping)

Wir vergleichen zwei Zeitreihen, z.â€¯B.:

```
A = [1, 2, 3]
B = [2, 2, 3, 4]
```

**Initialisierung:**
- MatrixgrÃ¶ÃŸe = len(A)+1 x len(B)+1
- Startpunkt (0,0) = 0, alle anderen Zellen âˆž
- Abstand: quadratischer Abstand: `(a_i - b_j)^2`

**Schritt-fÃ¼r-Schritt-FÃ¼llung:**
```
DTW[0][0] = 0

FÃ¼r alle i, j:
DTW[i][j] = (A[i-1] - B[j-1])^2 + min(
    DTW[i-1][j],     # EinfÃ¼gen
    DTW[i][j-1],     # LÃ¶schen
    DTW[i-1][j-1]    # Match
)
```

**Beispielhafte Matrix fÃ¼r A=[1,2,3], B=[2,2,3,4] (gekÃ¼rzt):**

|   |   | 2 | 2 | 3 | 4 |
|---|---|---|---|---|---|
|   | 0 | âˆž | âˆž | âˆž | âˆž |
| 1 | âˆž | 1 | 1 | 5 | 14 |
| 2 | âˆž | 1 | 1 | 2 | 6 |
| 3 | âˆž | 2 | 2 | 1 | 2 |

â†’ Der optimale Pfad (Warping Path) verlÃ¤uft dort, wo die kumulierten Kosten am niedrigsten sind.  
â†’ **DTW-Abstand = 2** (unterste rechte Ecke)

---

### Anwendung:
- Basis fÃ¼r Edit-Distanzen, DTW, Alignment-Algorithmen
- Sehr effizient bei rekursiven Problemen

ðŸ”— [Video: Dynamische Programmierung einfach erklÃ¤rt (Teil 1)](https://www.youtube.com/watch?v=oNoILrFOx2k)  
ðŸ”— [Video: Dynamische Programmierung einfach erklÃ¤rt (Teil 2)](https://www.youtube.com/watch?v=aPQY__2H3tE)


## 5. Needleman-Wunsch-Algorithmus

Ein auf dynamischer Programmierung basierender Algorithmus zur **globalen Sequenz-Ausrichtung**.

### Beispiel:
```
A: G A T T A C A  
B: G C A T G C U

Alignment:
G A T T A - C A
|   | |     | |
G C A T - G C U
```

### Anwendung:
- Sprachvergleiche Ã¼ber gesamte ZeitrÃ¤ume
- UrsprÃ¼nglich fÃ¼r Bioinformatik, heute auch in Audioanalyse genutzt

ðŸ”— [YouTube: Needleman-Wunsch Algorithmus erklÃ¤rt (Deutsch)](https://www.youtube.com/watch?v=Lsa-VfSQgt4)

---

## 6. Damerau-Levenshtein-Abstand

Erweiterung der Levenshtein-Distanz: erlaubt zusÃ¤tzlich **Vertauschung benachbarter Zeichen (Transposition)**.

### Beispiel:
```
"ca" â†’ "ac"
â†’ Levenshtein: 2 (LÃ¶schen + EinfÃ¼gen)
â†’ Damerau-Levenshtein: 1 (Vertauschung)
```

### Anwendung:
- Besseres Modell fÃ¼r reale Tippfehler
- NÃ¼tzlich bei Tastatureingaben und ASR

ðŸ”— [Wikipedia: Damerau-Levenshtein Distance (engl.)](https://en.wikipedia.org/wiki/Damerauâ€“Levenshtein_distance)

---

## 7. Dynamic Time Warping (DTW)

Ein DP-basierter Algorithmus, der **Ã¤hnliche Zeitreihen unterschiedlicher LÃ¤nge** vergleicht (z.â€¯B. Audiosignale).

### Beispiel:
```
Signal A: [1, 2, 3, 4, 5]
Signal B: [1, 1.5, 2.5, 4, 5]

â†’ DTW â€žverzerrtâ€œ die Zeitachse, um optimale Ãœbereinstimmung zu finden.
```

### Anwendung:
- Spracherkennung
- Audio-Matching
- Musikvergleich

ðŸ”— [Wikipedia: Dynamic Time Warping](https://de.wikipedia.org/wiki/Dynamic_Time_Warping)  
ðŸ”— [YouTube: DTW Explained â€“ Part 1](https://www.youtube.com/watch?v=_K1OsqCicBY)  
ðŸ”— [YouTube: DTW Explained â€“ Part 2](https://www.youtube.com/watch?v=ERKDHZyZDwA)

---