---
layout: page
title: SQL1 - comparing sequences
permalink: /notizen/Sequence_Learning/sql1/
---

# comparing sequences

## 1. Hamming-Abstand

Der **Hamming-Abstand** zÃ¤hlt, **wie viele Stellen sich zwei gleich lange Bitfolgen unterscheiden**.

### Beispiel:
```
A: 1 0 1 1 0 0 1  
B: 1 0 0 1 1 0 1

Unterschiede an Position 3 und 5  
â†’ Hamming-Abstand = 2
```

### Anwendung:
- Vergleich von Audiosignalen oder BinÃ¤rmerkmalen
- Fehlererkennung bei DatenÃ¼bertragung

ğŸ”— [Wikipedia: Hamming-Abstand](https://de.wikipedia.org/wiki/Hamming-Abstand)

---

## 2. Edit-/Levenshtein-Abstand

ZÃ¤hlt die **minimale Anzahl an Operationen** (EinfÃ¼gen, LÃ¶schen, Ersetzen), um eine Zeichenfolge in eine andere umzuwandeln.

### Beispiel:
```
"kitten" â†’ "sitting"
1. kitten â†’ sitten   (k â†’ s)
2. sitten â†’ sittin   (e â†’ i)
3. sittin â†’ sitting  (g anhÃ¤ngen)

â†’ Levenshtein-Abstand = 3
```

### Anwendung:
- Spracherkennung (z.â€¯B. erkannte WÃ¶rter vs. Zieltext)
- Rechtschreibkorrektur
- Ã„hnlichkeitsmessung

ğŸ”— [Wikipedia: Levenshtein-Distanz](https://de.wikipedia.org/wiki/Levenshtein-Distanz)

---

## 3. Edit-Transcript / Alignment

Das **Edit-Transcript** beschreibt die **Reihenfolge der Schritte** (Insert, Delete, Substitute), um eine Sequenz in eine andere zu Ã¼berfÃ¼hren.

### Beispiel:
```
A: kitten  
B: sitting

Transcript:
S(k â†’ s), S(e â†’ i), I(g)

Alignment (vereinfacht):
k i t t e n
| | | | | |
s i t t i n g
```

### Anwendung:
- Visualisierung von Fehlern bei automatischer Spracherkennung
- Auswertung von Vorhersagegenauigkeit

ğŸ”— [Lecture Slide Beispiel (engl.) mit Edit Transcripts](https://web.stanford.edu/class/cs124/lec/med.pdf)

---

## 4. Dynamische Programmierung (DP)

**Grundprinzip**, bei dem groÃŸe Probleme in **Ã¼berlappende Teilprobleme** zerlegt und deren LÃ¶sungen **gespeichert (Memoization)** werden.

### Beispiel fÃ¼r Levenshtein:
FÃ¼r die WÃ¶rter `kitten` und `sitting` wird eine Matrix erstellt, die jede mÃ¶gliche Kombination von Teilstrings speichert. So wird Schritt fÃ¼r Schritt die minimale Anzahl von Ã„nderungen bestimmt, statt alles mehrfach zu berechnen.

### Beispiel fÃ¼r DTW:
FÃ¼r zwei Zeitreihen z.â€¯B. `[1, 2, 3]` und `[1, 1.5, 2.5, 3]` wird eine Matrix aufgebaut, die die Abweichung jedes Punktepaares misst. Durch â€Verzerrenâ€œ der Zeitachsen wird der optimal passende Pfad gefunden.

### Anwendung:
- Basis fÃ¼r Edit-Distanzen, DTW, Alignment-Algorithmen
- Sehr effizient bei rekursiven Problemen

ğŸ”— [Video: Dynamische Programmierung einfach erklÃ¤rt (Teil 1)](https://www.youtube.com/watch?v=oNoILrFOx2k)  
ğŸ”— [Video: Dynamische Programmierung einfach erklÃ¤rt (Teil 2)](https://www.youtube.com/watch?v=aPQY__2H3tE)

---

## 5. Needleman-Wunsch-Algorithmus

Ein auf dynamischer Programmierung basierender Algorithmus zur **globalen Sequenz-Ausrichtung**.

### Beispiel:
```
A: G A T T A C A  
B: G C A T G C U

Alignment:
G A T T A - C A
|   | |     | |
G C A T - G C U
```

### Anwendung:
- Sprachvergleiche Ã¼ber gesamte ZeitrÃ¤ume
- UrsprÃ¼nglich fÃ¼r Bioinformatik, heute auch in Audioanalyse genutzt

ğŸ”— [YouTube: Needleman-Wunsch Algorithmus erklÃ¤rt (Deutsch)](https://www.youtube.com/watch?v=Lsa-VfSQgt4)

---

## 6. Damerau-Levenshtein-Abstand

Erweiterung der Levenshtein-Distanz: erlaubt zusÃ¤tzlich **Vertauschung benachbarter Zeichen (Transposition)**.

### Beispiel:
```
"ca" â†’ "ac"
â†’ Levenshtein: 2 (LÃ¶schen + EinfÃ¼gen)
â†’ Damerau-Levenshtein: 1 (Vertauschung)
```

### Anwendung:
- Besseres Modell fÃ¼r reale Tippfehler
- NÃ¼tzlich bei Tastatureingaben und ASR

ğŸ”— [Wikipedia: Damerau-Levenshtein Distance (engl.)](https://en.wikipedia.org/wiki/Damerauâ€“Levenshtein_distance)

---

## 7. Dynamic Time Warping (DTW)

Ein DP-basierter Algorithmus, der **Ã¤hnliche Zeitreihen unterschiedlicher LÃ¤nge** vergleicht (z.â€¯B. Audiosignale).

### Beispiel:
```
Signal A: [1, 2, 3, 4, 5]
Signal B: [1, 1.5, 2.5, 4, 5]

â†’ DTW â€verzerrtâ€œ die Zeitachse, um optimale Ãœbereinstimmung zu finden.
```

### Anwendung:
- Spracherkennung
- Audio-Matching
- Musikvergleich

ğŸ”— [Wikipedia: Dynamic Time Warping](https://de.wikipedia.org/wiki/Dynamic_Time_Warping)  
ğŸ”— [YouTube: DTW Explained â€“ Part 1](https://www.youtube.com/watch?v=_K1OsqCicBY)  
ğŸ”— [YouTube: DTW Explained â€“ Part 2](https://www.youtube.com/watch?v=ERKDHZyZDwA)

---
